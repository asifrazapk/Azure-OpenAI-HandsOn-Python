{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded ai_impact.txt to Blob Storage.\n",
      "Uploaded climate_change.txt to Blob Storage.\n",
      "Uploaded space_exploration.txt to Blob Storage.\n",
      "Uploaded quantum_computing.txt to Blob Storage.\n",
      "Uploaded sustainable_energy.txt to Blob Storage.\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Define Blob Storage details\n",
    "account_name = \"XXX\"\n",
    "account_key = \"XXX\"\n",
    "AZURE_STORAGE_CONNECTION_STRING = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "CONTAINER_NAME = 'XXXX'\n",
    "\n",
    "# Initialize Blob Storage client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)\n",
    "container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
    "\n",
    "# Upload text files to Blob Storage\n",
    "def upload_documents_to_blob(documents):\n",
    "    try:\n",
    "        for i, (file_name, content) in enumerate(documents.items()):\n",
    "            blob_client = container_client.get_blob_client(file_name)\n",
    "            blob_client.upload_blob(content, overwrite=True)\n",
    "            print(f\"Uploaded {file_name} to Blob Storage.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading documents: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example documents\n",
    "documents = {\n",
    "    \"ai_impact.txt\": \"Artificial intelligence is transforming various industries. Brand:Tahoe, Model:T21\",\n",
    "    \"climate_change.txt\": \"Climate change is one of the most pressing global challenges. Brand:Tracker, Model:DXL TR21\",\n",
    "    \"space_exploration.txt\": \"Recent advancements in space technology are remarkable. Brand:Regency, Model:RX 23\",\n",
    "    \"quantum_computing.txt\": \"The impact of quantum computing on cryptography is profound. Brand:Mako, Model:M233\",\n",
    "    \"sustainable_energy.txt\": \"Sustainable energy solutions are crucial for combating climate change.Brand:Nitro, Model:NN44\"\n",
    "}\n",
    "\n",
    "upload_documents_to_blob(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search index created successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import SearchIndex, SimpleField, SearchFieldDataType, SearchableField\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Azure Cognitive Search details\n",
    "search_service_name = \"XXXX\"\n",
    "admin_api_key = \"XXXX\"\n",
    "index_name = \"XXXX\" #define new name\n",
    "\n",
    "# Initialize Search Index client\n",
    "endpoint = f\"https://{search_service_name}.search.windows.net\"\n",
    "credential = AzureKeyCredential(admin_api_key)\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "\n",
    "# Define the index schema\n",
    "def create_search_index():\n",
    "    try:\n",
    "        fields = [\n",
    "            SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "            SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "            SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "            SearchableField(name=\"author\", type=SearchFieldDataType.String),\n",
    "            SimpleField(name=\"date\", type=SearchFieldDataType.String),\n",
    "            SearchableField(name=\"category\", type=SearchFieldDataType.String),\n",
    "            SearchableField(name=\"summary\", type=SearchFieldDataType.String),\n",
    "            SearchableField(name=\"brand\", type=SearchFieldDataType.String),\n",
    "            SearchableField(name=\"model\", type=SearchFieldDataType.String)\n",
    "        ]\n",
    "        \n",
    "        index = SearchIndex(name=index_name, fields=fields)\n",
    "        index_client.create_index(index)\n",
    "        print(\"Search index created successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating search index: {e}\")\n",
    "        raise\n",
    "\n",
    "create_search_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand: Tahoe\n",
      "Model: T21\n",
      "documents {'id': 'ai_impact', 'content': 'Artificial intelligence is transforming various industries. Brand:Tahoe, Model:T21', 'title': 'Sample Title', 'author': 'Author Name', 'date': '2024-07-25', 'category': 'Category', 'summary': 'Summary of the document', 'brand': 'Tahoe', 'model': 'T21'}\n",
      "Brand: Tracker\n",
      "Model: DXL\n",
      "documents {'id': 'climate_change', 'content': 'Climate change is one of the most pressing global challenges. Brand:Tracker, Model:DXL TR21', 'title': 'Sample Title', 'author': 'Author Name', 'date': '2024-07-25', 'category': 'Category', 'summary': 'Summary of the document', 'brand': 'Tracker', 'model': 'DXL'}\n",
      "Brand: Mako\n",
      "Model: M233\n",
      "documents {'id': 'quantum_computing', 'content': 'The impact of quantum computing on cryptography is profound. Brand:Mako, Model:M233', 'title': 'Sample Title', 'author': 'Author Name', 'date': '2024-07-25', 'category': 'Category', 'summary': 'Summary of the document', 'brand': 'Mako', 'model': 'M233'}\n",
      "Brand: Regency\n",
      "Model: RX\n",
      "documents {'id': 'space_exploration', 'content': 'Recent advancements in space technology are remarkable. Brand:Regency, Model:RX 23', 'title': 'Sample Title', 'author': 'Author Name', 'date': '2024-07-25', 'category': 'Category', 'summary': 'Summary of the document', 'brand': 'Regency', 'model': 'RX'}\n",
      "Brand: Nitro\n",
      "Model: NN44\n",
      "documents {'id': 'sustainable_energy', 'content': 'Sustainable energy solutions are crucial for combating climate change.Brand:Nitro, Model:NN44', 'title': 'Sample Title', 'author': 'Author Name', 'date': '2024-07-25', 'category': 'Category', 'summary': 'Summary of the document', 'brand': 'Nitro', 'model': 'NN44'}\n",
      "Documents indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "import re\n",
    "\n",
    "def get_brand_model(text):\n",
    "\n",
    "    # Regular expression to find Brand and Model\n",
    "    brand_pattern = r\"Brand:([A-Za-z0-9]+)\"\n",
    "    model_pattern = r\"Model:([A-Za-z0-9]+)\"\n",
    "\n",
    "    # Finding Brand and Model using regular expressions\n",
    "    brand = re.search(brand_pattern, text)\n",
    "    model = re.search(model_pattern, text)\n",
    "\n",
    "    # Extracting the values\n",
    "    brand_value = brand.group(1) if brand else None\n",
    "    model_value = model.group(1) if model else None\n",
    "\n",
    "    print(f\"Brand: {brand_value}\")\n",
    "    print(f\"Model: {model_value}\")\n",
    "\n",
    "    return brand_value,model_value\n",
    "\n",
    "def index_documents():\n",
    "    try:\n",
    "        search_client = SearchClient(\n",
    "            endpoint=endpoint,\n",
    "            index_name=index_name,\n",
    "            credential=credential\n",
    "        )\n",
    "\n",
    "        documents = []\n",
    "        container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
    "        \n",
    "        # Iterate over blobs in the container and create documents\n",
    "        blob_list = container_client.list_blobs()\n",
    "        for blob in blob_list:\n",
    "            blob_client = container_client.get_blob_client(blob)\n",
    "            content = blob_client.download_blob().readall().decode('utf-8')\n",
    "\n",
    "            brand, model = get_brand_model(content)\n",
    "            # Assuming each document has metadata\n",
    "            doc = {\n",
    "                \"id\": blob.name.split('.')[0],  # Using file name as id\n",
    "                \"content\": content,\n",
    "                \"title\": \"Sample Title\",  # Replace with actual metadata\n",
    "                \"author\": \"Author Name\",\n",
    "                \"date\": \"2024-07-25\",\n",
    "                \"category\": \"Category\",\n",
    "                \"summary\": \"Summary of the document\",\n",
    "                \"brand\":brand,\n",
    "                \"model\":model\n",
    "            }\n",
    "            print(\"documents\", doc)\n",
    "\n",
    "            documents.append(doc)\n",
    "        # Upload documents to the index\n",
    "        search_client.upload_documents(documents)\n",
    "        print(\"Documents indexed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error indexing documents: {e}\")\n",
    "        raise\n",
    "\n",
    "index_documents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Artificial intelligence is transforming various industries. Brand:Tahoe, Model:T21\n",
      "Title: Sample Title\n",
      "Author: Author Name\n",
      "Date: 2024-07-25\n",
      "Category: Category\n",
      "Summary: Summary of the document\n",
      "Score: 0.9808292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def search(query_text, top_k=2):\n",
    "    try:\n",
    "        search_client = SearchClient(\n",
    "            endpoint=endpoint,\n",
    "            index_name=index_name,\n",
    "            credential=credential\n",
    "        )\n",
    "        \n",
    "        results = search_client.search(query_text, top=top_k)\n",
    "        return [(result[\"content\"], result, result[\"@search.score\"]) for result in results]\n",
    "    except Exception as e:\n",
    "        print(f\"Error performing search: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage\n",
    "query_text = \"tahoe\"\n",
    "results = search(query_text)\n",
    "\n",
    "for result in results:\n",
    "    text, metadata, score = result\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Title: {metadata['title']}\")\n",
    "    print(f\"Author: {metadata['author']}\")\n",
    "    print(f\"Date: {metadata['date']}\")\n",
    "    print(f\"Category: {metadata['category']}\")\n",
    "    print(f\"Summary: {metadata['summary']}\")\n",
    "    print(f\"Score: {score}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
